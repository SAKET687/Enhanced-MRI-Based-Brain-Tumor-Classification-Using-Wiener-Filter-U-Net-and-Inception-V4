{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d7029a",
   "metadata": {},
   "source": [
    "Noise Suppression and Normalization and Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa174bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opencv-python numpy tqdm scikit-image matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b134730b",
   "metadata": {},
   "source": [
    "Application of Anisotropic Diffusion filtering and CLAHE[Contrast Limited Adaptive Histogram Equalization]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221c0a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Anisotropic Diffusion Function ===\n",
    "def anisotropic_diffusion(img, niter=10, kappa=50, gamma=0.1, option=1):\n",
    "    img = img.astype('float32')\n",
    "    for i in range(niter):\n",
    "        nablaN = np.roll(img, -1, axis=0) - img\n",
    "        nablaS = np.roll(img, 1, axis=0) - img\n",
    "        nablaE = np.roll(img, -1, axis=1) - img\n",
    "        nablaW = np.roll(img, 1, axis=1) - img\n",
    "\n",
    "        if option == 1:\n",
    "            cN = np.exp(-(nablaN / kappa) ** 2)\n",
    "            cS = np.exp(-(nablaS / kappa) ** 2)\n",
    "            cE = np.exp(-(nablaE / kappa) ** 2)\n",
    "            cW = np.exp(-(nablaW / kappa) ** 2)\n",
    "        elif option == 2:\n",
    "            cN = 1.0 / (1.0 + (nablaN / kappa) ** 2)\n",
    "            cS = 1.0 / (1.0 + (nablaS / kappa) ** 2)\n",
    "            cE = 1.0 / (1.0 + (nablaE / kappa) ** 2)\n",
    "            cW = 1.0 / (1.0 + (nablaW / kappa) ** 2)\n",
    "\n",
    "        img += gamma * (cN * nablaN + cS * nablaS + cE * nablaE + cW * nablaW)\n",
    "    return img\n",
    "\n",
    "# === Paths ===\n",
    "# Define the base path and result path\n",
    "\n",
    "base_path = 'brain_tumor_dataset'\n",
    "result_path = os.path.join(base_path, 'result')\n",
    "\n",
    "# Ensure result subfolders exist\n",
    "for subfolder in ['yes', 'no']:\n",
    "    os.makedirs(os.path.join(result_path, subfolder), exist_ok=True)\n",
    "\n",
    "# Process both 'yes' and 'no' folders\n",
    "for label in ['yes', 'no']:\n",
    "    folder_path = os.path.join(base_path, label)\n",
    "    save_path = os.path.join(result_path, label)\n",
    "    # Ensure the save path exists\n",
    "    for filename in tqdm(os.listdir(folder_path), desc=f'Processing {label}'):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            # Apply filtering\n",
    "            diffused = anisotropic_diffusion(img, niter=15, kappa=30, gamma=0.2) # Anisotropic diffusion filtering\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)) # Contrast Limited Adaptive Histogram Equalization\n",
    "            enhanced = clahe.apply(diffused.astype('uint8')) # Apply CLAHE\n",
    "\n",
    "            # Save to category-specific folder\n",
    "            name, ext = os.path.splitext(filename)\n",
    "            cv2.imwrite(os.path.join(save_path, f\"{label}_{name}_org.png\"), img)\n",
    "            cv2.imwrite(os.path.join(save_path, f\"{label}_{name}_op.png\"), enhanced)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c406fa",
   "metadata": {},
   "source": [
    "DIfference between original image and output image and errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273b424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, img_as_float\n",
    "from skimage.transform import resize\n",
    "from skimage.metrics import mean_squared_error, peak_signal_noise_ratio, structural_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# === Paths ===\n",
    "base_result = 'brain_tumor_dataset/result'\n",
    "heatmap_base = os.path.join(base_result, 'heatmaps')\n",
    "output_txt = os.path.join(base_result, 'results.txt')\n",
    "\n",
    "# Ensure heatmap subfolders exist\n",
    "for category in ['yes', 'no']:\n",
    "    os.makedirs(os.path.join(heatmap_base, category), exist_ok=True)\n",
    "\n",
    "# Clear or create the results file\n",
    "with open(output_txt, 'w') as f:\n",
    "    f.write(\"Filename\\t\\tMSE\\t\\tPSNR(dB)\\tSSIM\\t\\tAvg_%_Mod\\n\")\n",
    "\n",
    "# Process images from result/yes and result/no\n",
    "for category in ['yes', 'no']:\n",
    "    category_path = os.path.join(base_result, category)\n",
    "\n",
    "    for file in os.listdir(category_path):\n",
    "        if file.endswith('_org.png'):\n",
    "            base_name = file.replace('_org.png', '')\n",
    "            org_path = os.path.join(category_path, file)\n",
    "            op_path = os.path.join(category_path, f\"{base_name}_op.png\")\n",
    "\n",
    "            if not os.path.exists(op_path):\n",
    "                continue\n",
    "\n",
    "            # Load images\n",
    "            img_original = io.imread(org_path, as_gray=True)\n",
    "            img_denoised = io.imread(op_path, as_gray=True)\n",
    "\n",
    "            # Resize if needed\n",
    "            if img_original.shape != img_denoised.shape:\n",
    "                img_denoised = resize(img_denoised, img_original.shape, anti_aliasing=True)\n",
    "\n",
    "            # Convert to float\n",
    "            img_original = img_as_float(img_original)\n",
    "            img_denoised = img_as_float(img_denoised)\n",
    "\n",
    "            # Compute metrics\n",
    "            mse = mean_squared_error(img_original, img_denoised)\n",
    "            psnr = peak_signal_noise_ratio(img_original, img_denoised)\n",
    "            ssim = structural_similarity(img_original, img_denoised, data_range=1.0)\n",
    "            mad = np.mean(np.abs(img_original - img_denoised))\n",
    "            percent_modified = mad * 100\n",
    "\n",
    "            # Write to text file\n",
    "            with open(output_txt, 'a') as f:\n",
    "                f.write(f\"{category}_{base_name}\\t{mse:.4f}\\t{psnr:.2f}\\t\\t{ssim:.4f}\\t\\t{percent_modified:.2f}\\n\")\n",
    "\n",
    "            # Save heatmap\n",
    "            diff = np.abs(img_original - img_denoised)\n",
    "            plt.imshow(diff, cmap='hot')\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout(pad=0)\n",
    "\n",
    "            heatmap_path = os.path.join(heatmap_base, category, f\"{base_name}_heatmap.png\")\n",
    "            plt.savefig(heatmap_path, bbox_inches='tight', pad_inches=0)\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04f38e2",
   "metadata": {},
   "source": [
    "Normalization and Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8fceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Paths ===\n",
    "base_path = 'brain_tumor_dataset/result'\n",
    "output_path = 'brain_tumor_dataset/normalized and standardized'\n",
    "\n",
    "# Create output dirs\n",
    "for label in ['yes', 'no']:\n",
    "    os.makedirs(os.path.join(output_path, label), exist_ok=True)\n",
    "\n",
    "# === Process images ===\n",
    "for label in ['yes', 'no']:\n",
    "    folder = os.path.join(base_path, label)\n",
    "    out_folder = os.path.join(output_path, label)\n",
    "\n",
    "    for file in tqdm(os.listdir(folder), desc=f\"Processing {label}\"):\n",
    "        if file.endswith('_op.png'):\n",
    "            img_path = os.path.join(folder, file)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            # Normalize to [0, 1]\n",
    "            img_norm = img.astype(np.float32) / 255.0\n",
    "\n",
    "            # Standardize to mean=0, std=1\n",
    "            mean = np.mean(img_norm)\n",
    "            std = np.std(img_norm)\n",
    "            if std == 0: std = 1e-6  # Avoid division by zero\n",
    "            img_std = (img_norm - mean) / std\n",
    "\n",
    "            # Rescale back to 0â€“255 for saving (optional for visualization)\n",
    "            img_out = cv2.normalize(img_std, None, 0, 255, cv2.NORM_MINMAX)\n",
    "            img_out = img_out.astype(np.uint8)\n",
    "\n",
    "            # Save\n",
    "            name, _ = os.path.splitext(file)\n",
    "            save_path = os.path.join(out_folder, f\"{name}_std.png\")\n",
    "            cv2.imwrite(save_path, img_out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
